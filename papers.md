# IR 2024-2025
## List of Papers

This is the list of papers you can use to build Part #2 of the IR 2024-2025 final exam. Some of them are not available for free download. The ones that are not available for free download are made available to you in the "Files" section of the Microsoft Teams channel of the course.

For any questions, please contact us.

### Classic IR

1. Paolo Boldi, Sebastiano Vigna. 2024. **The WebGraph framework I: Compression Techniques**. The WebConf. ([paper](https://vigna.di.unimi.it/ftp/papers/WebGraphI.pdf))([code](https://github.com/vigna/webgraph-rs))

2. Samy Chambi, Daniel Lemire, Owen Kaser, Robert Godin. 2016. **Better bitmap performance with Roaring bitmaps**. Software: Practice and Experience. ([paper](http://arxiv.org/abs/1402.6407))([code](https://roaringbitmap.org/))

3. Peter Boncz, Thomas Neumann, Viktor Leis. 2020. **FSST: Fast static symbol table compression**. Proceedings of the VLDB. ([paper](https://www.vldb.org/pvldb/vol13/p2649-boncz.pdf))([code](https://github.com/cwida/fsst))

4. Omar Khattab, Mohammad Hammoud, Tamer Elsayed. 2020. **Finding the best of both worlds: faster and more robust top-k document retrieval**. SIGIR. ([paper](https://web2.qatar.cmu.edu/~mhhammou/SIGIR_20_LazyBM.pdf))

### Learning to Rank

5. Gabriele Capannini, Claudio Lucchese, Franco Maria Nardini, Salvatore Orlando, Raffaele Perego, Nicola Tonellotto. 2016. **Quality versus efficiency in document scoring with learning-to-rank models**. Information Processing and Management. PDF uploaded on Teams.

6. Domenico Dato, Sean MacAvaney, Franco Maria Nardini, Raffaele Perego, Nicola Tonellotto. 2022. **The Istella22 Dataset: Bridging Traditional and Neural Learning to Rank Evaluation**. SIGIR. ([paper](https://dl.acm.org/doi/10.1145/3477495.3531740))([code](https://github.com/hpclab/istella22-experiments))

7. Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, Tie-Yan Liu. 2017. **LightGBM: A Highly Efficient Gradient Boosting Decision Tree**. NeurIPS. ([paper](https://proceedings.neurips.cc/paper_files/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf))([code](https://github.com/microsoft/LightGBM))

8. Tianqi Chen, Carlos Guestrin. 2016. **XGBoost: A Scalable Tree Boosting System**. KDD. ([paper](https://www.kdd.org/kdd2016/papers/files/rfp0697-chenAemb.pdf))([code](https://github.com/dmlc/xgboost))

### Neural IR
   
9. Sebastian Bruch, Franco Maria Nardini, Cosimo Rulli, Rossano Venturini. 2024. **Efficient Inverted Indexes for Approximate Retrieval over Learned Sparse Representations**. SIGIR. ([paper](https://arxiv.org/abs/2404.18812))([code](https://github.com/TusKANNy/seismic))

10. Thibault Formal, Carlos Lassance, Benjamin Piwowarski, Stéphane Clinchant. 2022. **From Distillation to Hard Negative Sampling: Making Sparse Neural IR Models More Effective**. SIGIR. ([paper](https://arxiv.org/abs/2205.04733))([code](https://github.com/naver/splade))

11. Jimmy Lin. 2024. **Operational Advice for Dense and Sparse Retrievers: HNSW, Flat, or Inverted Indexes?**. ArXiv. ([paper](https://arxiv.org/abs/2409.06464))

12. Jingtao Zhan, Jiaxin Mao, Yiqun Liu, Jiafeng Guo, Min Zhang, Shaoping Ma. 2022. **Optimizing Dense Retrieval Model Training with Hard Negatives**. [paper](https://jiafengguo.github.io/2021/2021-Optimizing%20Dense%20Retrieval%20Model%20Training%20with%20Hard%20Negatives.pdf). [code](https://github.com/jingtaozhan/DRhard).

13. Sheng-Chieh Lin, Akari Asai, Minghan Li, Barlas Oguz, Jimmy Lin, Yashar Mehdad, Wen-tau Yih, and Xilun Chen. 2023. **How to Train Your DRAGON: Diverse Augmentation Towards Generalizable Dense Retrieval**. EMNLP. ([paper](https://aclanthology.org/2023.findings-emnlp.423.pdf))([code](https://github.com/facebookresearch/dpr-scale))

14. Sean MacAvaney, Nicola Tonellotto. 2024. **A Reproducibility Study of PLAID**. SIGIR. ([paper](https://arxiv.org/abs/2404.14989))([code](https://github.com/seanmacavaney/plaidrepro))

15. Jeff Johnson, Matthijs Douze, Hervé Jégou. 2017. **Billion-scale similarity search with GPUs**. ArXiv. [paper](https://github.com/facebookresearch/faiss). [code](https://github.com/facebookresearch/faiss).

16. Hervé Jégou, Matthijs Douze, Cordelia Schmid. 2011. **Product Quantization for Nearest Neighbor Search**. TPAMI. PDF uploaded on Teams.
